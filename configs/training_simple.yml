train_hyperparams:
  batch_size: 1
  epochs: 5
  lr: 1e-5

clip:
  model_name: "openai/clip-vit-base-patch32"

models:
  MultiModalClassifier:
    embed_dim: 512
    num_classes: 2
    num_heads: 4
    num_layers: 4
    hidden_dim: 128